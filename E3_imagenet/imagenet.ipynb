{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82863984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import captum.attr \n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4602ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "home_dir = '/home/luxburg/fgoeppert26/'\n",
    "torch.hub.set_dir(home_dir+'.local/.cache/torch')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84af9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_attributions(examples, baselines, model_dict, method_dict):\n",
    "    \n",
    "    model_attributions = {}\n",
    "   \n",
    "    examples.to(device)\n",
    "    examples = examples.double()\n",
    "    if baselines is None:\n",
    "        baselines = torch.rand((5,examples.shape[1],examples.shape[2],examples.shape[3]))\n",
    "    baselines.to(device)\n",
    "    \n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f'{model_name}:')\n",
    "        model_attributions[model_name] = []\n",
    "        \n",
    "        model.to(device) \n",
    "        model = model.double()\n",
    "        model = model.eval()\n",
    "        \n",
    "        targets = model(examples).argmax(1).to(device)\n",
    "        \n",
    "        #print(targets)\n",
    "            \n",
    "        attributions = {}\n",
    "        for method_name, method in method_dict.items():\n",
    "            meth = method[0](model) \n",
    "            if method[1]: \n",
    "                attr = meth.attribute(examples, baselines, target = targets, n_samples=5, stdevs=1.0) \n",
    "            else:\n",
    "                if method_name == 'gradient':\n",
    "                    attr = meth.attribute(examples, target = targets, abs = False)\n",
    "                else:\n",
    "                    attr = meth.attribute(examples, target = targets)\n",
    "                    \n",
    "            attributions[method_name] = attr.cpu().detach().numpy()\n",
    "            print(f'\\t {method_name} done!')\n",
    "            \n",
    "        model_attributions[model_name] = attributions \n",
    "        model.to('cpu')\n",
    "        \n",
    "    return model_attributions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9a9a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load some images from the imagenet12 validation set\n",
    "imagenet_dir = '/mnt/qb/datasets/ImageNet2012/val/n01531178'\n",
    "\n",
    "examples = []\n",
    "for file in os.listdir(imagenet_dir):\n",
    "    im = Image.open(imagenet_dir+'/'+file)\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    ])\n",
    "    im = transform(im)\n",
    "    examples.append(im)\n",
    "\n",
    "examples = torch.stack(examples)\n",
    "idx = [46,18,13]\n",
    "pkl.dump(examples[idx],open(f'examples.pkl)', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca05e91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxburg/fgoeppert26/.local/lib/python3.8/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t gradient done!\n",
      "\t input x gradient done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxburg/fgoeppert26/.local/lib/python3.8/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:60: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "vgg16:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "squeezenet:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "shufflenet:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "resnet18:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "wide_resnet50_2:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "inception:\n",
      "\t gradient done!\n",
      "\t input x gradient done!\n",
      "\t guided backprop done!\n",
      "\t gradient shap done!\n",
      "resnext50_32x4d:\n"
     ]
    }
   ],
   "source": [
    "# explain some examples using different models and methods\n",
    "\n",
    "examples = pkl.load(open(f'examples.pkl)', 'rb')\n",
    "baselines = None\n",
    "model_dict = {'alexnet': models.alexnet(pretrained=True),\n",
    "              'vgg16': models.vgg16(pretrained=True),\n",
    "              'squeezenet': models.squeezenet1_0(pretrained=True),\n",
    "              'shufflenet': models.shufflenet_v2_x1_0(pretrained=True),\n",
    "              'resnet18':models.resnet18(pretrained=True),\n",
    "              'wide_resnet50_2': models.wide_resnet50_2(pretrained=True),\n",
    "              'inception': models.inception_v3(pretrained=True),\n",
    "              'resnext50_32x4d': models.resnext50_32x4d(pretrained=True),\n",
    "              'googlenet': models.googlenet(pretrained=True),\n",
    "              'mnasnet': models.mnasnet1_0(pretrained=True)\n",
    "             }\n",
    "method_dict = {'gradient': (captum.attr.Saliency,False), \n",
    "               'input x gradient': (captum.attr.InputXGradient,False),\n",
    "               'guided backprop': (captum.attr.GuidedBackprop, False),\n",
    "               'gradient shap': (captum.attr.GradientShap,True),\n",
    "               }\n",
    "\n",
    "model_attributions = generate_attributions(normalize(examples), baselines, model_dict, method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c93860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# average attributions\n",
    "def generate_average_attributions(model_attributions):\n",
    "    mean_attributions = {}\n",
    "    for method_name in next(iter(model_attributions.values())):\n",
    "        method_attributions = [model_attributions[model_name][method_name] for model_name in model_attributions]\n",
    "        mean_attributions[method_name] = np.mean(np.array(method_attributions),axis = 0)\n",
    "    return mean_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46059d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# e.g. as extra entry\n",
    "model_attributions['mean attributions'] = generate_average_attributions(model_attributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93495ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot example and its attributions\n",
    "\n",
    "i = 2\n",
    "im = examples[i]\n",
    "n_models = len(model_dict)\n",
    "n_methods = len(method_dict) \n",
    "\n",
    "fig, ax = plt.subplots(nrows= n_methods+1,ncols = n_models+2, figsize=(12,5))\n",
    "c = 0                 \n",
    "r = 0            \n",
    "ax[r,c].imshow(im.permute(1,2,0), vmin=im.min(), vmax=im.max())\n",
    "ax[r,c].set_title('input')\n",
    "\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.axis('off')\n",
    "\n",
    "for model_name, attributions in model_attributions.items():\n",
    "    c += 1 \n",
    "    r = 0\n",
    "    color = 'black'\n",
    "    if model_name == 'mean attributions':\n",
    "        color = 'blue'\n",
    "        model_name = 'average'\n",
    "\n",
    "    for method_name,attr in attributions.items():\n",
    "        r += 1\n",
    "\n",
    "        a = abs(np.sum(attr[i],axis = 0)) # sum attributions over channels\n",
    "        \n",
    "        ax[r,c].imshow(a,cmap = 'Greys', vmax =a.max()*0.5)\n",
    "        if c == 1:\n",
    "            ax[r,c].text(-20,100,f'{method_name}',fontsize = 14,va = 'center', ha = 'right')\n",
    "        if r == 1:\n",
    "            ax[r,c].set_title(f'{model_name}', fontsize = 14, rotation=45, ha ='left', color = color)\n",
    "            \n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0)\n",
    "plt.savefig(f'imagenet.pdf',bbox_inches='tight',pad_inches=0.01)\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99418911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
